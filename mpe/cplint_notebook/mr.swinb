<div class="notebook hide-navbar open-fullscreen">

<div class="nb-cell html" name="htm13">
<h1>Mendelian Randomization as a Probabilistic Logic Program </h1>
This interactive notebook demonstrates <a href="https://www.bristol.ac.uk/integrative-epidemiology/mendelian-randomization/"> Mendelian Randomization </a> as a Probabilistic Logic Program, implemented on Cplint on SWISH [Alberti 2017, Wielemaker 2015]. 
The formalism used is Causal Probabilistic Logic (CP-Logic)[Vennekens 2009]. 
We aim to demonstrate some examples of using this formalism first, and then give some background information on the formalism later. 
The aim is to show how computational thinking can help us as MR researchers by applying automatic reasoning techniques to augment our reasoning around MR [Kowalski 2011].
We also give a different perspective to the common Causal Baysain Network (CBN) with Directed Acyclic Graph (DAG) and structured models approach which may widen our opportunity to think about the properties of MR.

<h4> The structure of the notebook is as follows: </h4>
<ol>
  <li> We describe three causal theories with some basic probablisitic queries. </li>
  <li> We explain how we normally calculate the causal effect with the 'do' operator. </li>
  <li> We explain a causal estimand using MR of the causal effect. </li>
  <li> We calculate this for the three theories. </li>
  <li> We explain how the equivalent of the 'do' operator is manifested in CP-logic. </li>
  <li> We modify the three theories with the intervention in a analogous way to using the 'do' operator, and make some probabilistic queries. Comparing them to MR estimates.</li>
  <li> We talk about the structure of the three theories, are they valid for MR? Is there selection bias, should we observe causal effects? </li>
  <li> We give more background on difference between CP-Logic and Causal Bayesian networks and structured models.</li>
  <li> We give a more complex example of family relationships with causal environmental transmission from parents to offspring. We also show how to sample from the causal theory to generate data such as trios or sibling pairs. </li>
  <li> Finally we describe some of the reasoning techniques available to us in various PLP implementations that may be useful for thinking about MR going forward.
</li></ol>
Throughout this note book we will use a number of artificial running examples.
In the first example we will define the relationships between a SNP (aa or ab), a metabolite (that can take on values 0 or 1) and having a high Body Mass Index (BMI).
<p>
We first set up our program by importing the required library and initializing it (line 1,2 and 3).
 In this note book we are using the approximate algorithms provided by the Mcintyre library [Riguzzi 2013]. 
We then state that our probabilistic program will begin (line 5) and on line 6 we state that someone has either the genotype value <i>aa</i> or <i>ab</i> with equal probability.


</p>
</div>

<div class="nb-cell program" data-background="true" name="p1">
:- use_module(library(clpfd)).
:- use_module(library(mcintyre)).
:- mc.

:- begin_lpad.
aa(_):0.5 ; ab(_):0.5.
</div>

<div class="nb-cell html" name="htm31">
<style>
h3 {text-align: center;}
</style>
<h3>Part 1 : Three Causal Theories</h3>
</div>

<div class="nb-cell html" name="htm12">
The following causal theory (CT1) is made from four causal laws (on lines 1,2, 4 &amp; 5).
It describes a set causal relationships between the genotype, the metabolite and having a high BMI.
It states if a person has the <i>aa</i> genotype, this will cause them to have the metabolite with value <i>1</i> with probability 0.7 or the value of the metabolite of <i>0</i> with probability 0.3 (line 1).
If they have the alternative genotype <i>ab</i>, this will instead cause them to have metabolite with value <i>1</i> with probability 0.2 or the value of the metabolite of <i>0</i> with probability 0.8 (line 2).

Regardless of the value of the genotype, if a person has metabolite version <i>1</i>, then this will cause them to have a high BMI (Value 1) with a probability of 0.6 or low BMI (Value 0) with probability 0.4 (line 4).
Alternatively if they have the <i>0</i> version of the metabolite, this will cause them to have a high BMI (Value 1) with probability of 0.3 or low BMI (Value 0) with probability 0.7 (line5). 
<p> Note: The connective operator <i>:-</i> is standard logic programming syntax and is intended to represent an arrow for logical implication. The semi colon ; represents disjunction and the comma , conjunction.</p>
</div>

<div class="nb-cell html" name="htm18">
<h5> Causal Theory 1 </h5>
</div>

<div class="nb-cell program" data-background="true" name="p2">
metabolite(X,1):0.7 ; metabolite(X,0):0.3 :- aa(X).
metabolite(X,1):0.2 ; metabolite(X,0):0.8 :- ab(X).

person_bmi(X,1):0.6 ; person_bmi(X,0):0.4 :- metabolite(X,1).
person_bmi(X,1):0.3 ; person_bmi(X,0):0.7 :- metabolite(X,0).
</div>

<div class="nb-cell html" name="htm1">
You can make an interactive query of this causal theory. 
For example in the next box clicking the run query button you will ask what the probability of someone having a high BMI is .
</div>

<div class="nb-cell html" name="htm19">
<h5> Query 1 (On CT1)</h5>
</div>

<div class="nb-cell query" name="q4">
mc_prob(person_bmi(X,1),P).
</div>

<div class="nb-cell html" name="htm7">
The next query uses the same causal theory (CT1) and asks what is the probability of a person having high BMI given they have metabolite <i>1</i>.
</div>

<div class="nb-cell html" name="htm20">
<h5> Query 2 (On CT1)</h5>
</div>

<div class="nb-cell query" name="q1">
mc_rejection_sample(person_bmi(X,1),metabolite(X,1),1000,P,[]).
</div>

<div class="nb-cell html" name="htm8">
And the next query asks the alternative:
</div>

<div class="nb-cell html" name="htm22">
<h5> Query 3 (On CT1) </h5>
</div>

<div class="nb-cell query" name="q6">
mc_rejection_sample(person_bmi(X,1),metabolite(X,0),1000,P,[]).
</div>

<div class="nb-cell html" name="htm29">
The risk difference is therefore:
</div>

<div class="nb-cell html" name="htm46">
<h5> Query 4 (On CT1) </h5>
</div>

<div class="nb-cell query" name="q12">
mc_rejection_sample(person_bmi(X,1),metabolite(X,1),1000,P1,[]), mc_rejection_sample(person_bmi(X,1),metabolite(X,0),1000,P2,[]), RiskDiffernce is P1-P2.
</div>

<div class="nb-cell html" name="htm2">
The next box gives an alternative causal theory (CT2). Which has a different set of causal relationships between the SNP, the metabolite and the state of having high BMI.
In this theory having the <i>aa</i> genotype causes a person to have the metabolite <i>1</i> with probability 0.6 or <i>0</i> with probability 0.3. 
However if they have the <i>ab</i> genotype this will cause them to have metabolite value <i>1</i> with probability 0.4 or metabolite value <i>0</i> with probability 0.6.

In contrast to the first causal theory, in this theory the state of having a high BMI is causally effected by the relationship between the genotype and the value of the metabolite.
<br>
Line 4, states that when a person has a metabolite <i>1</i> and genotype <i>ab</i> they will a high BMI with probability 0.3.
<br>
Line 5, states that when a person has metabolite version <i>1</i> but the genotype <i>aa</i> this will cause them to have a high BMI with probability 0.6.
<br>
Line 6, states that when a person has metabolite version <i>0</i> and the <i>ab</i> genotype this will cause them to have a high BMI with probability 0.4.
<br>
Lastly, line 7 states that with metabolite <i>0</i> and <i>aa</i>, this will cause high BMI with probability 0.5
</div>

<div class="nb-cell html" name="htm23">
<h5> Causal theory 2 </h5>
</div>

<div class="nb-cell program" data-background="true" name="p4">
metabolite_v2(X,1):0.2 ; metabolite_v2(X,0):0.8 :- aa(X).
metabolite_v2(X,1):0.4 ; metabolite_v2(X,0):0.6 :- ab(X).

person_bmi_v2(X,1):0.3 ; person_bmi_v2(X,0):0.7 :-metabolite_v2(X,1),ab(X).
person_bmi_v2(X,1):0.6 ; person_bmi_v2(X,0):0.4 :-metabolite_v2(X,1),aa(X).
person_bmi_v2(X,1):0.4 ; person_bmi_v2(X,0):0.6 :-metabolite_v2(X,0),ab(X).
person_bmi_v2(X,1):0.5 ; person_bmi_v2(X,0):0.5 :-metabolite_v2(X,0),aa(X).
</div>

<div class="nb-cell html" name="htm17">
However asking the same question "what is the probability of someone having a high BMI?" we get approximately the same probability.
</div>

<div class="nb-cell html" name="htm24">
<h5> Query 5 (On CT2)</h5>
</div>

<div class="nb-cell query" name="q2">
mc_prob(person_bmi_v2(X,1),P).
</div>

<div class="nb-cell html" name="htm14">
And then the conditional probabilities questions
</div>

<div class="nb-cell html" name="htm21">
<h5> Query 6 (On CT2)</h5>
</div>

<div class="nb-cell query" name="q8">
mc_rejection_sample(person_bmi_v2(X,1),metabolite_v2(X,1),1000,P,[]).
</div>

<div class="nb-cell html" name="htm28">
<h5> Query 7 (On CT2) </h5>
</div>

<div class="nb-cell query" name="q9">
mc_rejection_sample(person_bmi_v2(X,1),metabolite_v2(X,0),1000,P,[]).
</div>

<div class="nb-cell html" name="htm47">
<h5> Query 8 (On CT2) </h5>
</div>

<div class="nb-cell query" name="q16">
mc_rejection_sample(person_bmi_v2(X,1),metabolite_v2(X,1),1000,P1,[]), mc_rejection_sample(person_bmi_v2(X,1),metabolite_v2(X,0),1000,P2,[]), RiskDiffernce is P1-P2.
</div>

<div class="nb-cell html" name="htm9">
In the next box we give a third causal theory (CT3). 
In this theory we modify the example to also model how eating cheese effects someone having high BMI. 

<p>
In line 1 we state that 50% of people eat cheese.
Line 3 and line 4 give the initial value of the metabolite caused by the genotype.
</p>
<p>
Line 6 gives the causal deterministic law that if someone does not eat cheese their metabolite value stays the same.
Line 7 states that if a person eats cheese, and there metabolic value caused by the genotype is 0, then there top up value of the metabolite is 1 with probability 0.8 or remains 0 with probability 0.2.
Line 8 states and that if some one eats cheese and their metabolite value is 1 from there genotype then there metabolite value remains 1.
</p>
<p>
Line 10 states that eating cheese causes a high BMI with probability 0.7.
Line 11 states even if someone does not eat cheese they may have a high BMI with probability 0.1.
</p>
It can be clearly seen that there is no causal law effecting BMI from the metabolite value.
</div>

<div class="nb-cell html" name="htm25">
<h5> Causal Theory 3 </h5>
</div>

<div class="nb-cell program" data-background="true" name="p5">
person_cheese(X,1):0.5 ; person_cheese(X,0):0.5.

metabolite_initial(X,1):0.6 ; metabolite_initial(X,0):0.4 :- aa(X).
metabolite_initial(X,1):0.4 ; metabolite_initial(X,0):0.6 :- ab(X).

metabolite_v3(X,Y) :- person_cheese(X,0), metabolite_initial(X,Y).
metabolite_v3(X,1):0.8 ; metabolite_v3(X,0):0.2  :- person_cheese(X,1), metabolite_initial(X,0).
metabolite_v3(X,1) :- person_cheese(X,1), metabolite_initial(X,1).

person_bmi_v3(X,1):0.7 ; person_bmi_v3(X,0):0.3 :- person_cheese(X,1).
person_bmi_v3(X,1):0.1 ; person_bmi_v3(X,0):0.9 :- person_cheese(X,0).
</div>

<div class="nb-cell html" name="htm10">
However if we query for the Risk difference between metabolites values and BMI we get a positive value. This is because they are both caused by eating cheese.
</div>

<div class="nb-cell html" name="htm44">
<h5> Query 9 (On CT3) </h5>
</div>

<div class="nb-cell query" name="q7">
mc_rejection_sample(person_bmi_v3(X,1),metabolite_v3(X,1),1000,P1,[]), mc_rejection_sample(person_bmi_v3(X,1),metabolite_v3(X,0),1000,P2,[]), RiskDiffernce is P1-P2.
</div>

<div class="nb-cell html" name="htm48">
So in summary in CT1 the metabolite effects BMI and there is association. 
In CT2 the metabolite together with the genotype effect BMI but there is very little association.
In CT3 the metabolite does not effect BMI but there is an association.
</div>

<div class="nb-cell html" name="htm32">
<style>
h3 {text-align: center;}
</style>
<h3> Part 2 : Causal effect, interventions and the 'do' operator</h3>
</div>

<div class="nb-cell html" name="htm3">
As epidemiologists we are of course interested in identifying causal modifiable risk factors for disease.

Perl [2009] has established that when calculating probabilities taking into account causality we must distinguish 'seeing' from 'doing'.

We have shown three causal theories in which some associations are similar but the underlying process for creating the data are different.
<p>


</p>
Using Perl's 'do' notation we want to calculate:

<script type="text/javascript">
$.getScript("https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"+
             "?config=TeX-MML-AM_CHTML",function() {MathJax.Hub.Queue(["Typeset",MathJax.Hub]);});
</script>
<h5> Equation 1 </h5>
 \[E[BMI|do(Metabolite=1)] - E[BMI|do(metabolite=0)] \]

<p> i.e we want to know how the expected value of BMI would change if we could modify the value of the metabolite.</p>
</div>

<div class="nb-cell html" name="htm33">
<style>
h3 {text-align: center;}
</style>
<h3> Part 3 : Instrumental variable MR estimates of causal effect</h3>
</div>

<div class="nb-cell html" name="htm15">
<script type="text/javascript">
$.getScript("https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"+
             "?config=TeX-MML-AM_CHTML",function() {MathJax.Hub.Queue(["Typeset",MathJax.Hub]);});
</script>

If we imagine we were given observational data from these three theories but not the theories themselves and we wanted try and estimate the causal effect of the metabolite on BMI we could attempt to apply the Instrumental Variable (IV) approach of MR.
IV MR requires three properties to make valid causal inferences [Davey Smith 2003] [Hernán 2020].
<ol>
  <li> The variant associates with the exposure.</li>
  <li> The variant does not associate with confounders.</li>
  <li> The variant is only associated with the outcome via the exposure.</li>
</ol>
We would be able to at least verify the first requirement of MR that the value of the metabolite is associated with the value of genotype in the three theories.
</div>

<div class="nb-cell html" name="htm26">
<script type="text/javascript">
$.getScript("https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"+
             "?config=TeX-MML-AM_CHTML",function() {MathJax.Hub.Queue(["Typeset",MathJax.Hub]);});
</script>


To check the first requirment we can calculate the risk difference of the metabolite given the genotype.
<h5> Equation 2 </h5>
\[Pr [metabolite = 1|genotype = aa] − Pr [metabolite =1|genotype = ab] &gt;0.\]
</div>

<div class="nb-cell html" name="htm49">
<h5> Query 10 (On CT1) </h5>
</div>

<div class="nb-cell query" name="q3">
mc_rejection_sample(metabolite(X,1),aa(X),1000,P1,[]), mc_rejection_sample(metabolite(X,1),ab(X),1000,P2,[]), Risk_difference is P1 - P2.
</div>

<div class="nb-cell html" name="htm50">
<h5> Query 11 (On CT2) </h5>
</div>

<div class="nb-cell query" name="q11">
mc_rejection_sample(metabolite_v2(X,1),ab(X),1000,P1,[]), mc_rejection_sample(metabolite_v2(X,1),aa(X),1000,P2,[]), Risk_difference is P1 - P2.
</div>

<div class="nb-cell html" name="htm51">
<h5> Query 12 (On CT3) </h5>
</div>

<div class="nb-cell query" name="q17">
mc_rejection_sample(metabolite_v3(X,1),aa(X),1000,P1,[]), mc_rejection_sample(metabolite_v3(X,1),ab(X),1000,P2,[]), Risk_difference is P1 - P2.
</div>

<div class="nb-cell html" name="htm52">
So we can see that in all three causal theories there is a risk difference/association.
</div>

<div class="nb-cell html" name="htm34">
<style>
h3 {text-align: center;}
</style>
<h3> Part 4 : MR applied to the three theories</h3>
</div>

<div class="nb-cell html" name="htm27">
<script type="text/javascript">
$.getScript("https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"+
             "?config=TeX-MML-AM_CHTML",function() {MathJax.Hub.Queue(["Typeset",MathJax.Hub]);});
</script>
Then using the instrumental variable of the genotype we could estimate the causal effect with the following equation [Hernán 2020]:
<h5> Equation 3 </h5>
\[Causal\_ effect =\frac{E [BMI |genotype= aa] − E [BMI |genotype = ab]}{E [Metabolite|genotype = aa] − E [Metabolite|genotype = ab]}\]
The following three queries implement equation 3 on each CT.
<h5> Query 13 (On CT1) </h5>
</div>

<div class="nb-cell query" name="q10">
mc_rejection_expectation(person_bmi(X,BMI),aa(X),10000,BMI,Ex_bmi_aa), mc_rejection_expectation(person_bmi(X,BMI),ab(X),10000,BMI,Ex_bmi_ab),
mc_rejection_expectation(metabolite(X,Met),aa(X),10000,Met,Ex_met_aa),
mc_rejection_expectation(metabolite(X,Met),ab(X),10000,Met,Ex_met_ab), Cause is (Ex_bmi_aa - Ex_bmi_ab)/(Ex_met_aa - Ex_met_ab).
</div>

<div class="nb-cell html" name="htm4">
This is as expected giving us an estimate that is compatible with what was specified on causal theory 1.
The same query on causal theory 2 however gives a different probability.
<h5> Query 14 (On CT2) </h5>
</div>

<div class="nb-cell query" name="q5">
mc_rejection_expectation(person_bmi_v2(X,BMI),aa(X),10000,BMI,Ex_bmi_aa), mc_rejection_expectation(person_bmi_v2(X,BMI),ab(X),10000,BMI,Ex_bmi_ab),
mc_rejection_expectation(metabolite_v2(X,Met),aa(X),10000,Met,Ex_met_aa),
mc_rejection_expectation(metabolite_v2(X,Met),ab(X),10000,Met,Ex_met_ab), Cause is (Ex_bmi_aa - Ex_bmi_ab)/(Ex_met_aa - Ex_met_ab).
</div>

<div class="nb-cell html" name="htm16">
And the query on the 3rd causal theory.
<h5> Query 15 (On CT3) </h5>
</div>

<div class="nb-cell query" name="q13">
mc_rejection_expectation(person_bmi_v3(X,BMI),aa(X),10000,BMI,Ex_bmi_aa), mc_rejection_expectation(person_bmi_v3(X,BMI),ab(X),10000,BMI,Ex_bmi_ab),
mc_rejection_expectation(metabolite_v3(X,Met),aa(X),10000,Met,Ex_met_aa),
mc_rejection_expectation(metabolite_v3(X,Met),ab(X),10000,Met,Ex_met_ab), Cause is (Ex_bmi_aa - Ex_bmi_ab)/(Ex_met_aa - Ex_met_ab).
</div>

<div class="nb-cell html" name="htm35">
<style>
h3 {text-align: center;}
</style>
<h3> Part 5 : Interventions in CP Logic, analogous to 'do'</h3>
</div>

<div class="nb-cell html" name="htm5">
<script type="text/javascript">
$.getScript("https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"+
             "?config=TeX-MML-AM_CHTML",function() {MathJax.Hub.Queue(["Typeset",MathJax.Hub]);});
</script>


As in actual fact we are using artificial theories we do have access to our causal theories. 
We can therefore reason about our causal theories to calculate probabilities of interventions. 
Formal definitions of interventions allow us to remove human judgment on effects.
Instead we need to 1) Describe a causal theory of our domain and 2) follow a fixed set of rules to reason about the theory.

<p>This is analogous to pearls do operator. </p>

<h6>Interventions</h6>


<p>
Some of the differences are: 
In CP-Logic interventions are not at the level
of random variables (i.e., atoms) as Pearl does, but instead interventions
add and/or prevent CP-laws to/in a theory.
</p>
<ol>
  <li>Perls interventions fix a value, they can not contain a probability distribution</li>
  <li>Perls interventions can not introduce new relationships between existing random variables</li>
  <li></li>
  <li></li>
</ol>

Interventions in CP-Logic are therefore slightly more fine grained than that of Pearl version of the  'do' operator, since we can
consider interventions that prohibit a single causal law (as in the above example),
whereas Pearl only considers interventions that prohibit all causal laws that affect
the value of a certain random variables. 


  
<p>
  Formally: </p>
Let C be a CP-theory. An intervention is a pair <i>(R, A)</i> with <i>R</i> a
subset of <i>C</i> (a preemption) and <i>A</i> a set of laws not in <i>C</i> (an addition). The result
of performing <i>(R, A)</i> on <i>C</i>, denoted <i>C↯(R, A)</i>, is the CP-theory <i>(C \ R) ∪ A</i>.

<p>

  We next present three further causal theories which are modified versions of the original cts.
We remove the first two laws and replace with a law. 
If we do this to the three causal theories then we can now see how the probabilities are now different in the modified theories.
And compare these to the MR estimates in part 4 of this notebook.
</p>
<p>
  Making an intervention on the metabolite does not change a probability of getting high bmi.
  In causal theory 3.
</p>
</div>

<div class="nb-cell html" name="htm36">
<style>
h3 {text-align: center;}
</style>
<h3> Part 6 : The three theories with intervention</h3>
</div>

<div class="nb-cell html" name="htm41">
<h5> Causal Theory 1 B </h5>
</div>

<div class="nb-cell program" name="p9">
/*
 * The following two laws are commented out from the original ct1.
metabolite_ct1_b(X,1):0.7 ; metabolite_ct1_b(X,0):0.3 :- aa(X).
metabolite_ct1_b(X,1):0.2 ; metabolite_ct1_b(X,0):0.8 :- ab(X).
*/
metabolite_ct1_b(X,1):0.5 ; metabolite_ct1_b(X,0):0.5. %This is added.

person_bmi_ct1_b(X,1):0.6 ; person_bmi_ct1_b(X,0):0.4 :- metabolite_ct1_b(X,1).
person_bmi_ct1_b(X,1):0.3 ; person_bmi_ct1_b(X,0):0.7 :- metabolite_ct1_b(X,0).
</div>

<div class="nb-cell html" name="htm11">
<h5> Query 16 (On CT1 B) </h5>
</div>

<div class="nb-cell query" name="q18">
mc_rejection_expectation(person_bmi_ct1_b(X,BMI),metabolite_ct1_b(X,1),10000,BMI,Ex_bmi_met1), mc_rejection_expectation(person_bmi_ct1_b(X,BMI),metabolite_ct1_b(X,0),10000,BMI,Ex_bmi_met0),Effect is Ex_bmi_met1 - Ex_bmi_met0.
</div>

<div class="nb-cell html" name="htm42">
<h5> Causal Theory 2 b </h5>
</div>

<div class="nb-cell program" name="p8">
/*
 * The following two laws are commented out from the original ct1.
metabolite_v2_b(X,1):0.2 ; metabolite_v2_b(X,0):0.8 :- aa(X).
metabolite_v2_b(X,1):0.4 ; metabolite_v2_b(X,0):0.6 :- ab(X).
*/

metabolite_v2_b(X,1):0.5 ; metabolite_v2_b(X,0):0.5. % added

person_bmi_v2_b(X,1):0.3 ; person_bmi_v2_b(X,0):0.7 :-metabolite_v2_b(X,1),ab(X).
person_bmi_v2_b(X,1):0.6 ; person_bmi_v2_b(X,0):0.4 :-metabolite_v2_b(X,1),aa(X).
person_bmi_v2_b(X,1):0.4 ; person_bmi_v2_b(X,0):0.6 :-metabolite_v2_b(X,0),ab(X).
person_bmi_v2_b(X,1):0.5 ; person_bmi_v2_b(X,0):0.5 :-metabolite_v2_b(X,0),aa(X).
</div>

<div class="nb-cell html" name="htm53">
<h5> Query 17 (On CT2 B) </h5>
</div>

<div class="nb-cell query" name="q19">
mc_rejection_expectation(person_bmi_v2_b(X,BMI),metabolite_v2_b(X,1),10000,BMI,Ex_bmi_met1), mc_rejection_expectation(person_bmi_v2_b(X,BMI),metabolite_v2_b(X,0),10000,BMI,Ex_bmi_met0),Effect is Ex_bmi_met1 - Ex_bmi_met0.
</div>

<div class="nb-cell html" name="htm43">
<h5> Causal Theory 3 b </h5>
</div>

<div class="nb-cell query" name="q14">
/*
person_cheese_b(X,1):0.5 ; person_cheese_b(X,0):0.5.

metabolite_initial_b(X,1):0.6 ; metabolite_initial_b(X,0):0.4 :- aa(X).
metabolite_initial_b(X,1):0.4 ; metabolite_initial_b(X,0):0.6 :- ab(X).

metabolite_v3_b(X,Y) :- person_cheese_b(X,0), metabolite_initial_b(X,Y).
metabolite_v3_b(X,1):0.8 ; metabolite_v3_b(X,0):0.2  :- person_cheese_b(X,1), metabolite_initial_b(X,0).
metabolite_v3_b(X,1) :- person_cheese_b(X,1), metabolite_initial_b(X,1).

person_bmi_v3_b(X,1):0.7 ; person_bmi_v3_b(X,0):0.3 :- person_cheese_b(X,1).
person_bmi_v3_b(X,1):0.1 ; person_bmi_v3_b(X,0):0.9 :- person_cheese_b(X,0).
*/
</div>

<div class="nb-cell query" name="q20">

</div>

<div class="nb-cell html" name="htm37">
<style>
h3 {text-align: center;}
</style>
<h3> Part 7 : The structure of the three theories </h3>

In the first theory there is no causal law where the genotype causes the high bmi directly, i.e. there is no horizontal pleiotropy.
It therefore is compatible with the IV and MR rules.

In the second theory there is horizontal pleiotropy, and so this explains why the query is incompatible with the calculation with the intervention.

In the third theory, there is no causal effect.

With a given causal theory the second and third rules of MR (). Are related to the idea of Proof in logic programming. i.e. is there a proof of an event that uses events that would break the MR rules.
This can be encoded as :
<h6> MR as a PLP </h6>
<p>
  The second and third rules of MR are normally given in the contexts of DAGS. 
  The corresponding ideas in a probabilistic logic program relate to proofs.
  Can you prove a path in a hyper-graph from one event to another?
  A hyper graph is a generalisation of a graph where edges are sets of nodes rather than pairs.
  The corresponding graph ideas such as a path remain the same but using the generalized version of an edge.
</p>
Satisfiability.
Learning from proofs.
</div>

<div class="nb-cell html" name="htm38">
<style>
h3 {text-align: center;}
</style>
<h3> Part 8 : CP logic compared to CBN and PCMS</h3>
</div>

<div class="nb-cell html" name="htm6">
<script type="text/javascript">
$.getScript("https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"+
             "?config=TeX-MML-AM_CHTML",function() {MathJax.Hub.Queue(["Typeset",MathJax.Hub]);});
</script>

<p> 
So far in this notebook we have tried to be example driven but we have yet to really explain what CP-Logic [Vennekens 2009] is and how it differs from other formalisms.
</p>
<p>
CP-Logic is a different formalism to Causal Bayesian Networks and Probabilistic Causal Models which are often used in MR research. 
The full details of this formalism, its capabilities and limitations are too detailed to fit in this poster and we refer the reader to the literature for the complete picture, but we will now try to give an overview of some of the properties and how they might be useful for MR research. (We also adapt some of the examples/ descriptions from Vennekens 2009).
</p>

<p>
CP-Logic integrates the work of both Perl [2009] and Shafer [1996] on causality and probability; it seeks to be a logical language that represents dynamic causal laws.
In CP-Logic a random variable is something that gets assigned a certain value at a certain time.
This is in contrast to Perl’s probabilistic causal models which represent the relations between RVs as they hold in stable states of the domain. In a PCM we do not care about which event causes the value of an RV, or when it happens. In this way CP-Logic comes from the Shafer school of thought in which when considering probability or causality he thinks we need to consider the  context of a particular story and how the domain evolves, Shafer formalizes this with probability trees. In a probability tree the domain starts out in one state, then an event happens which causes the domain to change to a new state. The new state is chosen probabilistically from a set of alternatives. This is then repeated, as different events happen the states changes probabilistically from the available alternatives of that state. This happens until no further events take place.
</p>

<p>
  CP Logic therefore offers a succinct syntax for describing classes of Shaferian probability trees, CP-logic has also been proven to be equivalent to the language  of Logic Programs with Annotated Disjunctions (LPADS)  which has the formal distribution semantics of Sato in which a logic programming rule has its head annotated with a probability and this  specifies a probability distribution over a set of possible world in terms of these individual probabilities on a rule head. This means it is also a <i>practical probabilistic programming language</i> as we have seen in this notebook. 
  CP-Logic defines theories as sets of causal laws in the form 'Head ← Body'.  
  The body can be any first order logic formula.
  The head contains a disjunction of atoms annotated with a probability, which are the possible effects of the law.
</p>

<p>
According to Shafer [1996] a Bayesian network can be seen as a description of a class of probability trees. CP-Logic can represent a Bayesian network and as we have also seen CP-logic represents a causal system in a modular way as a set of causal laws. For this reason CP Logic
is also more expressive. In a process corresponding to a Bayesian network, the value of each random variable is determined by a single event but CP-logic allows multiple events to affect the same property.

Example, consider the results of a GWAS where two independent SNPs have been found to be associated with a high bmi:
</p><p>
  In CP-Logic:

\[High\_bmi :1/6:- SNP1\]
\[High\_bmi :1/6:- SNP2\]

</p>
<p>
  There are two “causal mechanisms” that might lead to high BMI:
 They are independent in the following sense: once we know how many and which of these mechanisms are actually activated (i.e., which versions of the two SNP are inherited), then observing whether one of these possible causes actually results in the effect provides no information about whether one of the other causes will cause the effect. 
  i.e., if both causal variants are inherited, then the probability of High BMI should be: \[Pr(high\_bmi) = 1 − (1 − 1/6)^2. \] (i.e. noisy or).
</p>
<p>
In the CP-theory, this independence is expressed by the structure of the theory, whereas in the Bayesian network, it is a numerical property of the probabilities in the conditional probability table for high BMI.
</p>
<p></p>
<p>
Because of this, the CP-theory is more elaboration tolerant, since adding or
removing an additional cause for high BMI simply corresponds to adding or removing
a single CP-law. Moreover, its representation is also more compact, requiring, in
general, only n probabilities for n independent causes, instead of the 2n entries that
are needed in a Bayesian network table.
</p>
<p>
Another feature is that in CP-logic, the cause of an event can be represented in a qualitative way, by means of a first-order formula. Bayesian networks, on the other hand, encode such
information in the probability tables. This means that it is possible to express very succinctly statements such as: <i> For all SNPS X, any SNP within LD that has genomic_feature, will cause Event with probability alpha. </i>, 

\[Event(X):Alpha :- within\_ld(x,y),genomic\_feature(y).\]

For example lets say there were 4 SNPs that were in linkage disequilibrium with genomic features in a standard BN you would need 2^4 many rows to represent this as opposed to this single CP-Law.
</p>
<p>
A further feature of CP-Logic is the ability to handle cyclic causal relations.

Consider:

\[high\_bmi:0.8 :- lack\_of\_exercise.\]
\[lack\_of\_exercise:0.7 :- high\_bmi.\]

This correctly behaves as follows if someone has neither a lack of exercise nor high bmi by an external cause then they will have neither. If they have a lack_of_exercise by an external cause, then with probability 0.8 he will also have high BMI.  If the person has high bmi by an external cause, then with probability 0.7 they will also have a lack of exercise.  If the person has both lack of exercise  and high bmi by an external cause, then they will obviously have both.
</p>
<p>
  In order to model this in a Bayesian network, you could introduce new, artificial random variables external(high bmi) and external(lack of exercise) to represent the possibility that high bmi and lack of exercise result from an external cause. But to encode a causal loop formed by n properties you would need to introduce n additional nodes.
</p>
<p>
As Epidemiologists we are interested in identifying why something has happened, this kind of diagnostic reasoning is the goal of <i>actual causation </i> and again Vennekens has argued that the formal semantics of CP-Logic has events which are not fully representable in CBN and structural equations and that CP-Logic is a better representation for this kind of reasoning. We will talk a little more about this kind of reasoning in the next part of the notebook, but one nuance I think is worth pondering on, is that often accounts of ‘actual causation’ or diagnostic reasoning address reasons for events in individuals but I think epidemiologists in public health are more concerned in reasoning around a kind of  ‘Average actual causation’ . That is the event that is caused is a distribution and we are interested in e.g. why the parameters of that distribution in a population are what they are, and how could we change them. For example the mean BMI is higher in group a to group b, why did that happen? 
</p>
<p>

Vennekens [2009] points out that Pearl uses two different languages when considering causal models, Bayesian networks and PCMS, (which are similar as every Bayesian network can be transformed into a PCM), but the different languages embody different  views on the nature of causality, Bayesian networks represent causal relations as inherently probabilistic, while PCMs express the Laplacian view that causal relations are completely deterministic and uncertainty stems solely from a lack of knowledge about their “inputs”. Pearl’s book adopts Bayesian networks throughout the chapters that first introduce the idea of interventions. When addressing the topic of counter factuals arises, a switch is made to the Laplacian view of PCMs.
</p>
<p>
  Vennekens remarks that it is peculiar that, on the one hand, interventions should be easiest to explain under the assumption that causal relations are inherently probabilistic, while on the other hand, their use for counter factual reasoning requires the assumption that causal relations are deterministic. 
</p>
<p>
  Vennekens argues in his paper that CP-logic’s event-based view on causality reconciles these two views: whether a Humean event happens is deterministic (in any given state of the world), but its outcome can be probabilistic. And therefore CP-logic can match Bayesian networks
as a natural representation for probabilistic causal relations, while also,  arguing that it surpasses PCMs as a counter factual reasoning tool.
</p>
<p>
  One of the aim of this poster/notebook is bring this formalism to greater attention of MR researchers and to show that this alternative formalism brings different capabilities and expressiveness to knowledge representation and reasoning required of MR research. 
</p>

<h5>Summary</h5>
<ol>
<li> CP-Logic explicitly represents time and events: An important part of reasoning about causality is time. 
 The fact that meiosis occurs necessarily before the other events can be modeled well in CP-Logic.  </li>
<li> CP-Logic is equivalent to practical probabilistic programming languages </li>
<li> CP-Logic is modular and a greater set of interventions can be considered compared to CBN and PCMs </li>
<li> CP-Logic can explicitly model multiple causes for one event, it can handle redundant causes i.e when something would cause an event but the event has already happened so it can not cause it. </li>
<li> CP-Logic is succinct, which can aid understanding and make machine learning of therioes potentially simpler  </li>
<li> CP-Logic is just different a method which gives a different view on causality</li>
</ol>
</div>

<div class="nb-cell html" name="htm39">
<style>
h3 {text-align: center;}
</style>
<h3> Part 9 : Family example and sampling data</h3>
</div>

<div class="nb-cell html" name="htm45">
We will now describe a more elaborate CT which is relevant to MR researchers thinking about within family studies.
When people are first introduced to programming in logic they are often given the task of writing programs about families. 
This is because the relationships can be very naturally represented and reasoned with.


Cite[ Within family Mendelian randomization studies]
cite [Avoiding dynastic, assortative mating, and population stratification biases in Mendelian randomization through within-family analyses]

In this CT we model mixed dynastic,genetic and enviromental effects on smoking and bmi.
We have a base case causal law for generation 0.
We then have a recursive causal law for further generations.
This models the mendelian laws of inherentnce.

BMI is a Gausain var.
Smoking is binary.
</div>

<div class="nb-cell program" name="p6">
parent_child(X,Y):- mother_child(X,Y).
parent_child(X,Y):- father_child(X,Y).

grandparent_child(X,Y):- parent_child(X,Z),parent_child(Z,Y).

ancestor(X,Y) :- parent_child(X,Y).
ancestor(X,Y) :- ancestor(X,Z),parent_child(Z,Y).

sibling(X,Y) :- parent_child(P,X),parent_child(P,Y).

cousin(X,Y):- parent_child(P1,X),sibling(P1,P2),parent_child(P2,Y).

child_aunt(X,Y):- parent_child(P,X),sibling(P,Y), female(Y).
child_uncle(X,Y):-parent_child(P,X),sibling(P,Y), male(Y).

%Generation 1 fixed
%Generation 2 probabilistic
</div>

<div class="nb-cell program" name="p10">
%smoking
%parents influence smoking
%advertising influences smoking
%gene influence smoking.
%:- use_module(library(clpr)).
smoke(I,yes):0.5; smoke(I,no):0.5 .

%smoke_p1_p2_gene(yes,P1,P2,G):X ; smoke_p1_p2_gene(no,P1,P2,G):Y: - true,X =2.

snp(X,1):0.5 ; snp(X,0):0.5.

bmi(_,X): gaussian(X,24,3). %Gausain mean 24, variance 3.
bmi_mean_var(X,Mean,Var): gaussian(X,Mean,Var). %Gausain mean M, variance V.

meiosis(_,C1-C2,C3-C4,C1-C3):0.25 ; meiosis(_,C1-C2,C3-C4,C1-C4):0.25 ;meiosis(_,C1-C2,C3-C4,C2-C3):0.25 ; meiosis(_,C1-C2,C3-C4,C2-C4):0.25.

%gen0 person
i_geno_pheno_gen_an(I,g(G1-G2,G3-G4),p(bmi(X),smoke(Smoke)),0,[]):-
    snp(1-I,G1), %alleles not snps!
    snp(2-I,G2),
    snp(3-I,G3),
    snp(4-I,G4),
    smoke(I,Smoke),
    bmi(I,X).

%gen x person.
i_geno_pheno_gen_an(I,g(G1-G2,G3-G4),p(bmi(BMI),smoke(yes)),Gen,parents(P1,P2)):-
    Gen0 #= Gen-1,
    i_geno_pheno_gen_an(m(I),g(P1_G1-P1_G2,P1_G3-P1_G4),p(bmi(P1_BMI),smoke(P1_Smoke)),Gen0,P1_Ancestors),
    P1 = i_geno_pheno_gen_an(m(I),g(P1_G1-P1_G2,P1_G3-P1_G4),p(bmi(P1_BMI),smoke(P1_Smoke)),Gen0,P1_Ancestors),
    i_geno_pheno_gen_an(f(I),g(P2_G1-P2_G2,P2_G3-P2_G4),p(bmi(P2_BMI),smoke(P2_Smoke)),Gen0,P2_Ancestors),
    P2 = i_geno_pheno_gen_an(f(I),g(P2_G1-P2_G2,P2_G3-P2_G4),p(bmi(P2_BMI),smoke(P2_Smoke)),Gen0, P2_Ancestors),                   
    meiosis(1,P1_G1-P1_G2, P2_G1-P2_G2, G1-G2),
    meiosis(2,P1_G3-P1_G4,P2_G3-P2_G4,G3-G4),
    BMI_Mean #= (P1_BMI+P2_BMI)/2,
    G1_Dosage #= (G1+G2),
    G1_effect_on_bmi #= G1_Dosage/10,
    New_bmi_mean #= BMI_Mean + G1_effect_on_bmi,
    bmi_mean_var(BMI,New_bmi_mean,3),
    true.

:- end_lpad.


%We can use the do operator with evidence of
</div>

<div class="nb-cell query" name="q15">
mc_sample_arg_first(i_geno_pheno_gen_an(one,Geno,Pheno,0,A),5,i_geno_pheno_gen_an(one,Geno,Pheno,0,A),Vs).
</div>

<div class="nb-cell query" name="q23">
Gen =1,mc_sample_arg_first(i_geno_pheno_gen_an(one,Geno,Pheno,Gen,A),5,i_geno_pheno_gen_an(one,Geno,Pheno,Gen,A),Vs), member(M-N,Vs), gvtree(M, A_tree).
</div>

<div class="nb-cell query" name="q22">
mc_sample_arg_first(bmi_mean_var(X,25,2),50,X,Vs).
</div>

<div class="nb-cell html" name="htm40">
<style>
h3 {text-align: center;}
</style>
<h3> Part 10 : Further reasoning techniques</h3>
<p>
In this notebook we have shown a number of PLPs that perform some epidemiological reasoning around MR in artificial examples.
We will now briefly discuss the wider field of artificial intelligence, automatic reasoning and how different techniques might be useful for MR methods researchers.
As we have seen, the tool of logic programming, especially in its probabilistic versions, is a useful and under-used tool in epidemiological research.
A major advantage to modeling MR approaches in a Probabilistic Logic Program is that the representation enables us to pose problems in which a large number of reasoning techniques have been implemented.
Of course epidemiologists have been using human logical reasoning in their research to try and understand the phenomena of interest, however augmenting this reasoning with automatic reasoning is potentially powerful and fruitful area of research, indeed recently there has been a number of efforts in other fields to apply these techniques for example the robot scientist [Sparkes 2010], which is able to form hypothesis and physically test them,  theory represenetation in pschology [Rohner 2021] and the new research starting on the robot computer scientist (http://autocs.co.uk/index.html) . 
We could ask what is the scope for a robot epidemiologists?
</p>
<p>
When considering what is practical to do now using existing implementations and ideas applied from this area of AI in epidemiology, the number of languages, systems, algorithms etc can be a little overwhelming and it has been referred to as alphabet soup of methods for some time [De Raedt 2008]. 
We hope to have shown in this poster/notebook that Cplint on Swish is a good place to start. 
It is a mature system, with many built in reasoning tools and there are a large number of examples and existing documentation and publications that people wanting to learn more can explore. 
We would also point out to the interested reader that basic introduction to programming in logic and artificial intelligent reasoning techniques can be found in [Flach 1994].  
One of the core ideas in this area is the automation of three reasoning techniques to make different types of inferences. 
These were first laid out by the philosopher Charles Pierce.
</p>
<h7>Pierce’s syllogisms.</h7>

<h6>Deduction.</h6>
All the beans from this bag are white.<br>
These beans are from this bag.<br>
Therefore: These beans are white.<br>

<h6>Induction.</h6>
These beans are [randomly selected] from this bag.<br>
These beans are white.<br>
Therefore: All the beans from this bag are white.<br>

<h6>Abduction.</h6>
All the beans from this bag are white.<br>
These beans are white.<br>
Therefore: These beans are from this bag. <br>
<br>
<p>
Both abduction and induction are so-called ampliative reasoning. 
This means that they <i>add </i>to existing knowledge as opposed to bringing out what is already there, however what it takes to justify a piece of inductive or abductive reasoning is not something that has been philosophically resolved [Flach 2013].
The corresponding research areas are Inductive Logic Programming (ILP), and Abductive Logic Programming (ALP). 
</p>
<p>
One of the most obvious tasks is to try and automatically learn our programs and causal theories from real observed data. 
This can be divided into two tasks, 1) Learning the structure of a program or causal theory or 2) given a structure/program learning the probabilistic parameters. 
We could potentially learn paramters for a fixed set of causal theories such as with or with out confounding elements and compare the results of the learning.
Cplint provides a number of algorithms for these tasks.  
Lemur [Di Mauro 2015] and Emblem [Bellodi 2013] are for learning parameters and Slipcover [Bellodi 2015] and PHIL [Fadja 2017] are for learning the structure of programs. 
Outside of Cplint,  state of the art non probabilistic ILP implementations have a number of useful features including predicate and object invention. 
In predicate invention new predicates are introduced to programs that do not have examples of these predicates. 
For example inventing the concept of mother or father as a female or male parent, when learning family relations. 
This can reduce the size of the program learnt as well as defining new concepts [Patsantzis 2021, Cropper 2021, Cropper 2016]. 
Object invention refers to adding objects to a theory, for example, saying that two nodes are connected in a graph, to explain why a path query is successful.  
In an MR context this could be introducing a postulated confounder for example. 
Two avenues for thinking about MR in this context are:
</p>
<ol>
  <li>Using the known rules of MR and causal constraints to inform the background knowledge and inductive bias of an ILP system.</li>
  <li>Using MR to justify or chose an abductive explanation. </li>
</ol>
<p>
Another aspect of automatic reasoning that has received attention is non-monotonic reasoning (when adding to a program can make previous conclusions invalid), including default reasoning and negation, (both default reasoning and negation are potentially important for causal modeling as discussed in [Vennekens 2011]) an example of a system that has been applied to revise metabolic networks is the XHAIL system [Ray 2009] .
Incorporating genetic associations and MR concepts as background knowledge in a similar system might help inform the search for good solutions to metabolic pathway construction and revision tasks. 
</p>
<p>
As we have said justifying one abduction over an another is a unsolved problem, sometimes many potential abductions could be made. 
We have also discussed a critical task in epidemiolgy - trying to distguish between different causal theories for our observed data.
I.e. is the true sitatuion ct1 or ct2, ct3 or a specilaistion or generalisation of these or another theory altogether.
MR methods seek to help us do this, by reasoning about how an association could occur and if it would meet certain constraints or what other consequences we might expect if an aspect of theory is true or false.
</p>
<p>
One method to choose a potential abductive explanation is the Most Probable Explanation (MPE) [Shterionov 2015].
However this works with one causal theory with multiple potential causes for an event.
This is where we calculate the possible worlds where the event is true, and then look to see which world is the most probable, and in that world what is the explanation for the event.
This reasoning is implemented in Cplint and we can see how ideas from MR could work with this example.
Abductive reasoning is related to the ideas of actual causation mentioned in part 8 of this notebook.
The distngushment is between; a) what are the potential reasons for an event and b) what actualy caused the event.
</p>
<p>
  In this program, lines 2,3,4 and set up the program to use the PITA inference method.
Then on lines 6 and 7 we have two causal laws that give alternative explanations for why a population might have high BMI.
Lines 9-12 give the probabitlies that certain properties, which are causes of high BMI are true in the population.
</p>
</div>

<div class="nb-cell html" name="htm55">
<h5> Causal theory X </h5>
</div>

<div class="nb-cell program" name="p7">
%MPE inference. Adapted from Shterionov 2015.
:- use_module(library(pita)).
:- pita.
:- begin_lpad.

high_bmi :- likes_cheese, lives_near_cheese_shop.
high_bmi :- sedetry_job, scared_of_gyms.

map_query 0.4::likes_cheese.
map_query 0.9::lives_near_cheese_shop.
map_query 0.5::sedetry_job.
map_query 0.6::scared_of_gyms.
</div>

<div class="nb-cell html" name="htm57">
<h5> Query Q on CTX </h5>
</div>

<div class="nb-cell query" name="q21">
map(high_bmi,P,Exp).
</div>

<div class="nb-cell html" name="htm54">
<p>

Asking the causal theory X in query Q, given high_bmi what is the most probable explantion? 
 This gives us an answer with a truth assignment to possible worlds.
  i.e. we see x,y,z is true. And therefore it is line 7 that gives us our explantion for our observation of high BMI.
</p>
<p>
Mpe inference can help us have a single explanation for an event with independent causes in a single causal theory at the object level. 
However we need to think about how we can reason to distguish explations at the theory rather than at the object level.
We would also like to generate abductive causal theories at differnt levels of generality, for example with unbound variables to represent any potential confounder rather than a specific measure confounder, or where confounders or an effect are constrained to be in a certain set of values.
This reasoing would require Constriant Logic Programming [2006], possibly with custom rules constraints. Constraint Handling Rules [Frühwirth 1998] is a language design to implement custom constraint systems.
</p>
<p>
Apart from Cplint we will also mention, another prominent PLP implementation: Problog [De Raedt 2007]. 
There is a variant of Problog called Algebraic Problog [Kimmig 2011] which is designed for reasoning across posible worlds including MPE inference and it is possible with its reasoning to identify constraints on confidence bounds which I think would be useful for many MR based tasks.
</p>
<p>
In this poster/notebook we have demonstrated basic MR ideas implemented as a PLP, the logic of more advance MR methods would be good to see. 
We also note that apart from the direct use of some of the algorithms developed for automatic reasoning Kowalski [2011] advocates that some of these and ways of thinking that have come out of AI research are also useful tools for human thinking in and of themselves, and applying these ideas in the context of MR would likely be insightful. 
</p>
</div>

<div class="nb-cell program" data-background="true" data-singleline="true" name="p3">
:- end_lpad.
</div>

<div class="nb-cell program" data-background="true" data-singleline="true" name="p11">
:- use_rendering(graphviz).
% from SWISH examples (https://swish.swi-prolog.org/example/render_graphviz.swinb)
tree(Compound, Root, Options0, Options) --&gt;
    { compound(Compound), !,
      atom_concat(n, Options0.id, Root),
      compound_name_arguments(Compound, Name, Arguments),
      format(string(Label), '~q', [Name]),
      ID1 is Options0.id+1
    },
    [node(Root, [label=Label])],
    children(Arguments, Root, Options0.put(id, ID1), Options).
tree(Any, Leaf, Options0, Options) --&gt;
    { atom_concat(n, Options0.id, Leaf),
      ID1 is Options0.id+1,
      any_label(Any, Label, Color),
      Options = Options0.put(id, ID1)
    },
    [ node(Leaf, [label=Label, shape=none, fontcolor=Color]) ].

any_label(Any, Label, red4) :-
    var(Any), !, Label = Any.
any_label(Any, Label, blue) :-
    format(string(Label), '~p', [Any]).

children([], _, Options, Options) --&gt; [].
children([H|T], Parent, Options0, Options) --&gt;
    [ Child -&gt; Parent ],
    tree(H, Child, Options0, Options1),
    children(T, Parent, Options1, Options).

gvtree(Term, digraph([rankdir='BT',size=5|Statements])) :-
    phrase(tree(Term, _, _{id:1}, _), Statements).
</div>

<div class="nb-cell html" name="htm30">
<p>Refs:</p>
<ol>
<li> Alberti, Marco, et al. "cplint on SWISH: Probabilistic logical inference with a web browser." Intelligenza Artificiale 11.1 (2017): 47-64. </li>
  <li> Wielemaker, Jan, Torbjörn Lager, and Fabrizio Riguzzi. "SWISH: SWI-Prolog for sharing." arXiv preprint arXiv:1511.00915 (2015).</li>
  <li> Vennekens, Joost, Marc Denecker, and Maurice Bruynooghe. "CP-logic: A language of causal probabilistic events and its relation to logic programming." arXiv preprint arXiv:0904.1672 (2009). </li>
<li>Kowalski, Robert. Computational logic and human thinking: how to be artificially intelligent. Cambridge University Press, 2011. </li>
<li> Riguzzi, Fabrizio. "MCINTYRE: A Monte Carlo system for probabilistic logic programming." Fundamenta Informaticae 124.4 (2013): 521-541. </li>
  <li> Pearl, Judea. Causality. Cambridge university press, 2009. </li>  
  <li> Davey Smith, George, and Shah Ebrahim. "‘Mendelian randomization’: can genetic epidemiology contribute to understanding environmental determinants of disease?." International journal of epidemiology 32.1 (2003): 1-22.</li>
  <li> Hernán, Miguel A., and James M. Robins. "Causal inference: what if." (2020): 69-80. </li>
  <li> Vennekens, Joost. "Actual causation in cp-logic." arXiv preprint arXiv:1107.4865 (2011). </li>
  <li> De Raedt, Luc, et al. "Towards digesting the alphabet-soup of statistical relational learning." NIPS* 2008 Workshop Probabilistic Programming, Date: 2008/12/13-2008/12/13, Location: Whistler, Canada. 2008.</li>
  <li> Patsantzis, Stassa, and Stephen H. Muggleton. "Top Program Construction and Reduction for polynomial time Meta-Interpretive Learning." arXiv preprint arXiv:2101.05050 (2021).</li>
  <li> Ray, Oliver. "Nonmonotonic abductive inductive learning." Journal of Applied Logic 7.3 (2009): 329-340. </li>
  <li> Cropper, Andrew, and Rolf Morel. "Learning programs by learning from failures." Machine Learning 110.4 (2021): 801-856. </li>
  <li> Cropper, Andrew, and Stephen H. Muggleton. "Learning higher-order logic programs through abstraction and invention." (2016). </li>
  <li> Flach, Peter. Simply logical: intelligent reasoning by example. John Wiley &amp; Sons, Inc., 1994. </li>
  <li> Bellodi, Elena, and Fabrizio Riguzzi. "Structure learning of probabilistic logic programs by searching the clause space." Theory and Practice of Logic Programming 15.2 (2015): 169-212. </li>
  <li> Bellodi, Elena, and Fabrizio Riguzzi. "Expectation Maximization over binary decision diagrams for probabilistic logic programs." Intelligent Data Analysis 17.2 (2013): 343-363. </li>
  A Causal Logic of Logic Programming 2003
  <li> Di Mauro, Nicola, Elena Bellodi, and Fabrizio Riguzzi. "Bandit-based Monte-Carlo structure learning of probabilistic logic programs." Machine Learning 100.1 (2015): 127-156. </li>
  <li> Fadja, Arnaud Nguembang, Evelina Lamma, and Fabrizio Riguzzi. "Deep Probabilistic Logic Programming." PLP@ ILP. 2017. </li>
  <li> De Raedt, Luc, Angelika Kimmig, and Hannu Toivonen. "ProbLog: A Probabilistic Prolog and Its Application in Link Discovery." IJCAI. Vol. 7. 2007. </li>
  <li> Kimmig, Angelika, Guy Van den Broeck, and Luc De Raedt. "An algebraic Prolog for reasoning about possible worlds." Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 25. No. 1. 2011. </li>
  <li> Shterionov, Dimitar, et al. "The most probable explanation for probabilistic logic programs with annotated disjunctions." Inductive Logic Programming. Springer, Cham, 2015. 139-153. </li>
  <li> Frühwirth, Thom. "Theory and practice of constraint handling rules." The Journal of Logic Programming 37.1-3 (1998): 95-138. </li>
  <li> Marriott, Kim, Peter J. Stuckey, and Mark Wallace. "Constraint logic programming." Foundations of Artificial Intelligence 2 (2006): 409-452. </li>
  <li> Rohner, Jean-Christophe, and Håkan Kjellerstrand. "Using logic programming for theory representation and scientific inference." New Ideas in Psychology 61 (2021): 100838.</li>
</ol>
</div>

<div class="nb-cell html" name="htm56">

</div>

</div>
